{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict if a YouTube comment is a spam\n",
    "### Import the data as pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Huh, anyway check out this you[tube] channel: ...\n",
       "1    Hey guys check out my new channel and our firs...\n",
       "2               just for test I have to say murdev.com\n",
       "3     me shaking my sexy ass on my channel enjoy ^_^ ﻿\n",
       "4              watch?v=vtaRGgvGtWQ   Check this out .﻿\n",
       "Name: CONTENT, dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_filenames = ['Youtube01-Psy.csv', 'Youtube02-KatyPerry.csv', 'Youtube03-LMFAO.csv', 'Youtube04-Eminem.csv']\n",
    "valid_filename = 'Youtube05-Shakira.csv'\n",
    "\n",
    "train_df = pd.concat([pd.read_csv('data/' + filename, encoding='utf-8-sig') for filename in train_filenames])\n",
    "\n",
    "train_df.CONTENT.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get words indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>CONTENT_WORDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU</td>\n",
       "      <td>Julius NM</td>\n",
       "      <td>2013-11-07T06:20:48</td>\n",
       "      <td>Huh, anyway check out this you[tube] channel: kobyoshi02</td>\n",
       "      <td>1</td>\n",
       "      <td>[huh, anyway, check, out, this, you, tube, channel, kobyoshi02]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A</td>\n",
       "      <td>adam riyati</td>\n",
       "      <td>2013-11-07T12:37:15</td>\n",
       "      <td>Hey guys check out my new channel and our first vid THIS IS US THE  MONKEYS!!! I'm the monkey in the white shirt,please leave a like comment  and please subscribe!!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>[hey, guys, check, out, my, new, channel, and, our, first, vid, this, is, us, the, monkeys, i, m, the, monkey, in, the, white, shirt, please, leave, a, like, comment, and, please, subscribe]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8</td>\n",
       "      <td>Evgeny Murashkin</td>\n",
       "      <td>2013-11-08T17:34:21</td>\n",
       "      <td>just for test I have to say murdev.com</td>\n",
       "      <td>1</td>\n",
       "      <td>[just, for, test, i, have, to, say, murdev, com]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z13jhp0bxqncu512g22wvzkasxmvvzjaz04</td>\n",
       "      <td>ElNino Melendez</td>\n",
       "      <td>2013-11-09T08:28:43</td>\n",
       "      <td>me shaking my sexy ass on my channel enjoy ^_^ ﻿</td>\n",
       "      <td>1</td>\n",
       "      <td>[me, shaking, my, sexy, ass, on, my, channel, enjoy, _]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z13fwbwp1oujthgqj04chlngpvzmtt3r3dw</td>\n",
       "      <td>GsMega</td>\n",
       "      <td>2013-11-10T16:05:38</td>\n",
       "      <td>watch?v=vtaRGgvGtWQ   Check this out .﻿</td>\n",
       "      <td>1</td>\n",
       "      <td>[watch, v, vtarggvgtwq, check, this, out]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    COMMENT_ID            AUTHOR  \\\n",
       "0  LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU         Julius NM   \n",
       "1  LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A       adam riyati   \n",
       "2  LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8  Evgeny Murashkin   \n",
       "3          z13jhp0bxqncu512g22wvzkasxmvvzjaz04   ElNino Melendez   \n",
       "4          z13fwbwp1oujthgqj04chlngpvzmtt3r3dw            GsMega   \n",
       "\n",
       "                  DATE  \\\n",
       "0  2013-11-07T06:20:48   \n",
       "1  2013-11-07T12:37:15   \n",
       "2  2013-11-08T17:34:21   \n",
       "3  2013-11-09T08:28:43   \n",
       "4  2013-11-10T16:05:38   \n",
       "\n",
       "                                                                                                                                                                  CONTENT  \\\n",
       "0                                                                                                                Huh, anyway check out this you[tube] channel: kobyoshi02   \n",
       "1  Hey guys check out my new channel and our first vid THIS IS US THE  MONKEYS!!! I'm the monkey in the white shirt,please leave a like comment  and please subscribe!!!!   \n",
       "2                                                                                                                                  just for test I have to say murdev.com   \n",
       "3                                                                                                                        me shaking my sexy ass on my channel enjoy ^_^ ﻿   \n",
       "4                                                                                                                                 watch?v=vtaRGgvGtWQ   Check this out .﻿   \n",
       "\n",
       "   CLASS  \\\n",
       "0      1   \n",
       "1      1   \n",
       "2      1   \n",
       "3      1   \n",
       "4      1   \n",
       "\n",
       "                                                                                                                                                                                    CONTENT_WORDS  \n",
       "0                                                                                                                                 [huh, anyway, check, out, this, you, tube, channel, kobyoshi02]  \n",
       "1  [hey, guys, check, out, my, new, channel, and, our, first, vid, this, is, us, the, monkeys, i, m, the, monkey, in, the, white, shirt, please, leave, a, like, comment, and, please, subscribe]  \n",
       "2                                                                                                                                                [just, for, test, i, have, to, say, murdev, com]  \n",
       "3                                                                                                                                         [me, shaking, my, sexy, ass, on, my, channel, enjoy, _]  \n",
       "4                                                                                                                                                       [watch, v, vtarggvgtwq, check, this, out]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import itertools\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "def replace_url(phrase):\n",
    "    urls = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', phrase)\n",
    "    for url in urls:\n",
    "        phrase = phrase.replace(url, 'URLURLURLURL')\n",
    "    return phrase\n",
    "\n",
    "def format_phrase(phrase):\n",
    "    #phrase = replace_url(phrase)\n",
    "    words = re.sub(\"[^\\w]\", \" \",  phrase).split()\n",
    "    #words = nltk.word_tokenize(phrase)\n",
    "    return [w.replace(\" \", \"\").lower() for w in words]\n",
    "    \n",
    "def get_unique_words(phrases):\n",
    "    words_list = phrases.sum()\n",
    "    return np.unique(np.array(words_list))\n",
    "\n",
    "def words2idxs(phrase):\n",
    "    words_count = len(word2idx)\n",
    "    return [word2idx[word] if word in word2idx else words_count for word in phrase]\n",
    "\n",
    "train_df = train_df.assign(CONTENT_WORDS=train_df.CONTENT.apply(format_phrase))\n",
    "\n",
    "unique_words = get_unique_words(train_df.CONTENT_WORDS)\n",
    "word2idx = {v: k for k, v in enumerate(unique_words)}\n",
    "\n",
    "pd.options.display.max_colwidth = 300\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agnes', 'blog', 'is', 'totally', 'awesome']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_phrase('Agnes Blog is totALLy awesome :) !!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>CONTENT_WORDS</th>\n",
       "      <th>CONTENT_IDX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU</td>\n",
       "      <td>Julius NM</td>\n",
       "      <td>2013-11-07T06:20:48</td>\n",
       "      <td>Huh, anyway check out this you[tube] channel: kobyoshi02</td>\n",
       "      <td>1</td>\n",
       "      <td>[huh, anyway, check, out, this, you, tube, channel, kobyoshi02]</td>\n",
       "      <td>[1839, 518, 861, 2626, 3500, 3911, 3590, 850, 2070]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A</td>\n",
       "      <td>adam riyati</td>\n",
       "      <td>2013-11-07T12:37:15</td>\n",
       "      <td>Hey guys check out my new channel and our first vid THIS IS US THE  MONKEYS!!! I'm the monkey in the white shirt,please leave a like comment  and please subscribe!!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>[hey, guys, check, out, my, new, channel, and, our, first, vid, this, is, us, the, monkeys, i, m, the, monkey, in, the, white, shirt, please, leave, a, like, comment, and, please, subscribe]</td>\n",
       "      <td>[1779, 1697, 861, 2626, 2456, 2492, 850, 493, 2625, 1482, 3692, 3500, 1957, 3649, 3477, 2407, 1855, 2252, 3477, 2406, 1899, 3477, 3807, 3130, 2746, 2122, 364, 2144, 937, 493, 2746, 3354]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8</td>\n",
       "      <td>Evgeny Murashkin</td>\n",
       "      <td>2013-11-08T17:34:21</td>\n",
       "      <td>just for test I have to say murdev.com</td>\n",
       "      <td>1</td>\n",
       "      <td>[just, for, test, i, have, to, say, murdev, com]</td>\n",
       "      <td>[2021, 1509, 3464, 1855, 1746, 3528, 3049, 2448, 929]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z13jhp0bxqncu512g22wvzkasxmvvzjaz04</td>\n",
       "      <td>ElNino Melendez</td>\n",
       "      <td>2013-11-09T08:28:43</td>\n",
       "      <td>me shaking my sexy ass on my channel enjoy ^_^ ﻿</td>\n",
       "      <td>1</td>\n",
       "      <td>[me, shaking, my, sexy, ass, on, my, channel, enjoy, _]</td>\n",
       "      <td>[2303, 3114, 2456, 3110, 560, 2592, 2456, 850, 1308, 348]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z13fwbwp1oujthgqj04chlngpvzmtt3r3dw</td>\n",
       "      <td>GsMega</td>\n",
       "      <td>2013-11-10T16:05:38</td>\n",
       "      <td>watch?v=vtaRGgvGtWQ   Check this out .﻿</td>\n",
       "      <td>1</td>\n",
       "      <td>[watch, v, vtarggvgtwq, check, this, out]</td>\n",
       "      <td>[3762, 3667, 3733, 861, 3500, 2626]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    COMMENT_ID            AUTHOR  \\\n",
       "0  LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU         Julius NM   \n",
       "1  LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A       adam riyati   \n",
       "2  LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8  Evgeny Murashkin   \n",
       "3          z13jhp0bxqncu512g22wvzkasxmvvzjaz04   ElNino Melendez   \n",
       "4          z13fwbwp1oujthgqj04chlngpvzmtt3r3dw            GsMega   \n",
       "\n",
       "                  DATE  \\\n",
       "0  2013-11-07T06:20:48   \n",
       "1  2013-11-07T12:37:15   \n",
       "2  2013-11-08T17:34:21   \n",
       "3  2013-11-09T08:28:43   \n",
       "4  2013-11-10T16:05:38   \n",
       "\n",
       "                                                                                                                                                                  CONTENT  \\\n",
       "0                                                                                                                Huh, anyway check out this you[tube] channel: kobyoshi02   \n",
       "1  Hey guys check out my new channel and our first vid THIS IS US THE  MONKEYS!!! I'm the monkey in the white shirt,please leave a like comment  and please subscribe!!!!   \n",
       "2                                                                                                                                  just for test I have to say murdev.com   \n",
       "3                                                                                                                        me shaking my sexy ass on my channel enjoy ^_^ ﻿   \n",
       "4                                                                                                                                 watch?v=vtaRGgvGtWQ   Check this out .﻿   \n",
       "\n",
       "   CLASS  \\\n",
       "0      1   \n",
       "1      1   \n",
       "2      1   \n",
       "3      1   \n",
       "4      1   \n",
       "\n",
       "                                                                                                                                                                                    CONTENT_WORDS  \\\n",
       "0                                                                                                                                 [huh, anyway, check, out, this, you, tube, channel, kobyoshi02]   \n",
       "1  [hey, guys, check, out, my, new, channel, and, our, first, vid, this, is, us, the, monkeys, i, m, the, monkey, in, the, white, shirt, please, leave, a, like, comment, and, please, subscribe]   \n",
       "2                                                                                                                                                [just, for, test, i, have, to, say, murdev, com]   \n",
       "3                                                                                                                                         [me, shaking, my, sexy, ass, on, my, channel, enjoy, _]   \n",
       "4                                                                                                                                                       [watch, v, vtarggvgtwq, check, this, out]   \n",
       "\n",
       "                                                                                                                                                                                  CONTENT_IDX  \n",
       "0                                                                                                                                         [1839, 518, 861, 2626, 3500, 3911, 3590, 850, 2070]  \n",
       "1  [1779, 1697, 861, 2626, 2456, 2492, 850, 493, 2625, 1482, 3692, 3500, 1957, 3649, 3477, 2407, 1855, 2252, 3477, 2406, 1899, 3477, 3807, 3130, 2746, 2122, 364, 2144, 937, 493, 2746, 3354]  \n",
       "2                                                                                                                                       [2021, 1509, 3464, 1855, 1746, 3528, 3049, 2448, 929]  \n",
       "3                                                                                                                                   [2303, 3114, 2456, 3110, 560, 2592, 2456, 850, 1308, 348]  \n",
       "4                                                                                                                                                         [3762, 3667, 3733, 861, 3500, 2626]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "train_df = train_df.assign(CONTENT_IDX=train_df.CONTENT_WORDS.apply(words2idxs))\n",
    "\n",
    "maxlen = train_df.CONTENT_IDX.map(len).max()\n",
    "train_content_idx = sequence.pad_sequences(train_df.CONTENT_IDX, maxlen=maxlen, value=-1)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_df = pd.read_csv('data/' + valid_filename, encoding='utf-8-sig')\n",
    "\n",
    "valid_df = valid_df.assign(CONTENT_WORDS=valid_df.CONTENT.apply(format_phrase))\n",
    "valid_df = valid_df.assign(CONTENT_IDX=valid_df.CONTENT_WORDS.apply(words2idxs))\n",
    "\n",
    "valid_content_idx = sequence.pad_sequences(valid_df.CONTENT_IDX, maxlen=maxlen, value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:10: UserWarning: The `dropout` argument is no longer support in `Embedding`. You can apply a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1586 samples, validate on 370 samples\n",
      "Epoch 1/10\n",
      "1586/1586 [==============================] - 0s - loss: 0.9965 - acc: 0.4994 - val_loss: 0.6727 - val_acc: 0.4703\n",
      "Epoch 2/10\n",
      "1586/1586 [==============================] - 0s - loss: 0.6185 - acc: 0.6690 - val_loss: 0.3236 - val_acc: 0.9081\n",
      "Epoch 3/10\n",
      "1586/1586 [==============================] - 0s - loss: 0.2466 - acc: 0.9161 - val_loss: 0.2291 - val_acc: 0.9324\n",
      "Epoch 4/10\n",
      "1586/1586 [==============================] - 0s - loss: 0.1277 - acc: 0.9697 - val_loss: 0.2014 - val_acc: 0.9297\n",
      "Epoch 5/10\n",
      "1586/1586 [==============================] - 0s - loss: 0.0975 - acc: 0.9773 - val_loss: 0.1858 - val_acc: 0.9459\n",
      "Epoch 6/10\n",
      "1586/1586 [==============================] - 0s - loss: 0.0692 - acc: 0.9874 - val_loss: 0.2132 - val_acc: 0.9378\n",
      "Epoch 7/10\n",
      "1586/1586 [==============================] - 0s - loss: 0.0669 - acc: 0.9868 - val_loss: 0.2143 - val_acc: 0.9405\n",
      "Epoch 8/10\n",
      "1586/1586 [==============================] - 0s - loss: 0.0761 - acc: 0.9842 - val_loss: 0.2436 - val_acc: 0.9297\n",
      "Epoch 9/10\n",
      "1586/1586 [==============================] - 0s - loss: 0.0597 - acc: 0.9893 - val_loss: 0.2362 - val_acc: 0.9378\n",
      "Epoch 10/10\n",
      "1586/1586 [==============================] - 0s - loss: 0.0671 - acc: 0.9905 - val_loss: 0.2699 - val_acc: 0.9297\n",
      "Train on 1586 samples, validate on 370 samples\n",
      "Epoch 1/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0630 - acc: 0.9905 - val_loss: 0.2566 - val_acc: 0.9432\n",
      "Epoch 2/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0677 - acc: 0.9880 - val_loss: 0.2649 - val_acc: 0.9405\n",
      "Epoch 3/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0792 - acc: 0.9887 - val_loss: 0.2768 - val_acc: 0.9297\n",
      "Epoch 4/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0601 - acc: 0.9937 - val_loss: 0.2785 - val_acc: 0.9378\n",
      "Epoch 5/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0804 - acc: 0.9868 - val_loss: 0.3584 - val_acc: 0.9324\n",
      "Epoch 6/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0663 - acc: 0.9912 - val_loss: 0.3694 - val_acc: 0.9270\n",
      "Epoch 7/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0798 - acc: 0.9893 - val_loss: 0.3923 - val_acc: 0.9297\n",
      "Epoch 8/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0712 - acc: 0.9912 - val_loss: 0.3316 - val_acc: 0.9351\n",
      "Epoch 9/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0594 - acc: 0.9937 - val_loss: 0.3688 - val_acc: 0.9270\n",
      "Epoch 10/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0650 - acc: 0.9924 - val_loss: 0.3709 - val_acc: 0.9216\n",
      "Epoch 11/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0543 - acc: 0.9956 - val_loss: 0.3736 - val_acc: 0.9297\n",
      "Epoch 12/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0646 - acc: 0.9931 - val_loss: 0.4890 - val_acc: 0.9081\n",
      "Epoch 13/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0602 - acc: 0.9931 - val_loss: 0.3972 - val_acc: 0.9135\n",
      "Epoch 14/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0530 - acc: 0.9943 - val_loss: 0.3864 - val_acc: 0.9189\n",
      "Epoch 15/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0676 - acc: 0.9899 - val_loss: 0.4263 - val_acc: 0.9297\n",
      "Epoch 16/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0780 - acc: 0.9880 - val_loss: 0.3751 - val_acc: 0.9297\n",
      "Epoch 17/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.1006 - acc: 0.9855 - val_loss: 0.4120 - val_acc: 0.9351\n",
      "Epoch 18/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0772 - acc: 0.9918 - val_loss: 0.3982 - val_acc: 0.9297\n",
      "Epoch 19/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0749 - acc: 0.9899 - val_loss: 0.3247 - val_acc: 0.9351\n",
      "Epoch 20/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0701 - acc: 0.9918 - val_loss: 0.3298 - val_acc: 0.9297\n",
      "Epoch 21/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0704 - acc: 0.9937 - val_loss: 0.3342 - val_acc: 0.9351\n",
      "Epoch 22/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0623 - acc: 0.9943 - val_loss: 0.3390 - val_acc: 0.9351\n",
      "Epoch 23/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0784 - acc: 0.9924 - val_loss: 0.3927 - val_acc: 0.9351\n",
      "Epoch 24/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0678 - acc: 0.9943 - val_loss: 0.3734 - val_acc: 0.9297\n",
      "Epoch 25/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0738 - acc: 0.9918 - val_loss: 0.4645 - val_acc: 0.9243\n",
      "Epoch 26/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0716 - acc: 0.9905 - val_loss: 0.3973 - val_acc: 0.9297\n",
      "Epoch 27/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0699 - acc: 0.9937 - val_loss: 0.3944 - val_acc: 0.9297\n",
      "Epoch 28/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0719 - acc: 0.9924 - val_loss: 0.3604 - val_acc: 0.9297\n",
      "Epoch 29/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0691 - acc: 0.9943 - val_loss: 0.3734 - val_acc: 0.9216\n",
      "Epoch 30/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0695 - acc: 0.9924 - val_loss: 0.3327 - val_acc: 0.9297\n",
      "Epoch 31/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0717 - acc: 0.9918 - val_loss: 0.4484 - val_acc: 0.9351\n",
      "Epoch 32/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0888 - acc: 0.9880 - val_loss: 0.3333 - val_acc: 0.9514\n",
      "Epoch 33/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0885 - acc: 0.9899 - val_loss: 0.4160 - val_acc: 0.9189\n",
      "Epoch 34/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0841 - acc: 0.9924 - val_loss: 0.4126 - val_acc: 0.9324\n",
      "Epoch 35/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0810 - acc: 0.9950 - val_loss: 0.3679 - val_acc: 0.9405\n",
      "Epoch 36/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0780 - acc: 0.9931 - val_loss: 0.4531 - val_acc: 0.9216\n",
      "Epoch 37/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0758 - acc: 0.9950 - val_loss: 0.3907 - val_acc: 0.9351\n",
      "Epoch 38/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0687 - acc: 0.9962 - val_loss: 0.3438 - val_acc: 0.9432\n",
      "Epoch 39/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0603 - acc: 0.9981 - val_loss: 0.3809 - val_acc: 0.9351\n",
      "Epoch 40/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0546 - acc: 0.9968 - val_loss: 0.4010 - val_acc: 0.9351\n",
      "Train on 1586 samples, validate on 370 samples\n",
      "Epoch 1/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0630 - acc: 0.9943 - val_loss: 0.3615 - val_acc: 0.9378\n",
      "Epoch 2/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0738 - acc: 0.9937 - val_loss: 0.4048 - val_acc: 0.9378\n",
      "Epoch 3/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0571 - acc: 0.9956 - val_loss: 0.5548 - val_acc: 0.9054\n",
      "Epoch 4/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0729 - acc: 0.9918 - val_loss: 0.4556 - val_acc: 0.9243\n",
      "Epoch 5/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.1074 - acc: 0.9836 - val_loss: 0.4000 - val_acc: 0.9324\n",
      "Epoch 6/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0857 - acc: 0.9918 - val_loss: 0.4596 - val_acc: 0.9189\n",
      "Epoch 7/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0859 - acc: 0.9943 - val_loss: 0.4239 - val_acc: 0.9108\n",
      "Epoch 8/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0763 - acc: 0.9962 - val_loss: 0.4171 - val_acc: 0.9189\n",
      "Epoch 9/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0778 - acc: 0.9956 - val_loss: 0.4541 - val_acc: 0.9108\n",
      "Epoch 10/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0907 - acc: 0.9899 - val_loss: 0.4472 - val_acc: 0.9135\n",
      "Epoch 11/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0839 - acc: 0.9912 - val_loss: 0.4022 - val_acc: 0.9189\n",
      "Epoch 12/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0783 - acc: 0.9937 - val_loss: 0.3962 - val_acc: 0.9270\n",
      "Epoch 13/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0652 - acc: 0.9950 - val_loss: 0.3716 - val_acc: 0.9378\n",
      "Epoch 14/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0663 - acc: 0.9950 - val_loss: 0.3921 - val_acc: 0.9405\n",
      "Epoch 15/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0731 - acc: 0.9956 - val_loss: 0.3775 - val_acc: 0.9324\n",
      "Epoch 16/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0782 - acc: 0.9918 - val_loss: 0.4236 - val_acc: 0.9216\n",
      "Epoch 17/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0812 - acc: 0.9905 - val_loss: 0.4053 - val_acc: 0.9297\n",
      "Epoch 18/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0806 - acc: 0.9943 - val_loss: 0.4017 - val_acc: 0.9297\n",
      "Epoch 19/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0752 - acc: 0.9943 - val_loss: 0.5340 - val_acc: 0.9108\n",
      "Epoch 20/40\n",
      "1586/1586 [==============================] - 0s - loss: 0.0760 - acc: 0.9931 - val_loss: 0.4808 - val_acc: 0.9270\n",
      "Epoch 21/40\n",
      "1586/1586 [==============================] - 1s - loss: 0.0729 - acc: 0.9931 - val_loss: 0.4616 - val_acc: 0.9189\n",
      "Epoch 22/40\n",
      "1586/1586 [==============================] - 2s - loss: 0.0715 - acc: 0.9962 - val_loss: 0.5165 - val_acc: 0.9135\n",
      "Epoch 23/40\n",
      "1586/1586 [==============================] - 2s - loss: 0.0775 - acc: 0.9937 - val_loss: 0.5477 - val_acc: 0.9162\n",
      "Epoch 24/40\n",
      "1586/1586 [==============================] - 2s - loss: 0.0724 - acc: 0.9950 - val_loss: 0.4174 - val_acc: 0.9243\n",
      "Epoch 25/40\n",
      "1586/1586 [==============================] - 2s - loss: 0.0769 - acc: 0.9918 - val_loss: 0.4424 - val_acc: 0.9270\n",
      "Epoch 26/40\n",
      "1586/1586 [==============================] - 2s - loss: 0.0736 - acc: 0.9931 - val_loss: 0.4746 - val_acc: 0.9243\n",
      "Epoch 27/40\n",
      "1586/1586 [==============================] - 2s - loss: 0.0636 - acc: 0.9956 - val_loss: 0.4928 - val_acc: 0.9216\n",
      "Epoch 28/40\n",
      "1586/1586 [==============================] - 2s - loss: 0.0641 - acc: 0.9956 - val_loss: 0.4374 - val_acc: 0.9216\n",
      "Epoch 29/40\n",
      "1586/1586 [==============================] - 2s - loss: 0.0642 - acc: 0.9962 - val_loss: 0.5453 - val_acc: 0.9135\n",
      "Epoch 30/40\n",
      "1586/1586 [==============================] - 2s - loss: 0.0605 - acc: 0.9981 - val_loss: 0.5891 - val_acc: 0.8973\n",
      "Epoch 31/40\n",
      "1586/1586 [==============================] - 2s - loss: 0.0642 - acc: 0.9943 - val_loss: 0.5561 - val_acc: 0.9162\n",
      "Epoch 32/40\n",
      "1586/1586 [==============================] - 2s - loss: 0.0690 - acc: 0.9962 - val_loss: 0.6899 - val_acc: 0.9162\n",
      "Epoch 33/40\n",
      "1586/1586 [==============================] - 2s - loss: 0.0786 - acc: 0.9924 - val_loss: 0.5420 - val_acc: 0.9135\n",
      "Epoch 34/40\n",
      "1586/1586 [==============================] - 2s - loss: 0.0681 - acc: 0.9962 - val_loss: 0.5262 - val_acc: 0.9189\n",
      "Epoch 35/40\n",
      "1586/1586 [==============================] - 2s - loss: 0.0634 - acc: 0.9962 - val_loss: 0.5171 - val_acc: 0.9081\n",
      "Epoch 36/40\n",
      "1586/1586 [==============================] - 2s - loss: 0.0628 - acc: 0.9962 - val_loss: 0.5310 - val_acc: 0.9135\n",
      "Epoch 37/40\n",
      "1586/1586 [==============================] - 2s - loss: 0.0551 - acc: 0.9981 - val_loss: 0.5111 - val_acc: 0.9189\n",
      "Epoch 38/40\n",
      "1586/1586 [==============================] - 2s - loss: 0.0636 - acc: 0.9956 - val_loss: 0.5730 - val_acc: 0.9162\n",
      "Epoch 39/40\n",
      "1586/1586 [==============================] - 2s - loss: 0.0699 - acc: 0.9931 - val_loss: 0.4667 - val_acc: 0.9216\n",
      "Epoch 40/40\n",
      "1586/1586 [==============================] - 2s - loss: 0.0759 - acc: 0.9937 - val_loss: 0.5201 - val_acc: 0.9216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fad004eb8d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import MaxPooling1D, Conv1D, BatchNormalization\n",
    "from keras.layers import Flatten, Dense, Embedding, Dropout, Dense, SpatialDropout1D\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam, Adamax, RMSprop, SGD\n",
    "from keras.regularizers import l2\n",
    "\n",
    "vocab_size = len(word2idx) + 1\n",
    "vgg_model = Sequential([\n",
    "    \n",
    "    Embedding(vocab_size, 32, input_length=maxlen, embeddings_regularizer=l2(1e-4), dropout=0.4),\n",
    "    Dropout(0.4),\n",
    "    \n",
    "    # Conv Block 1\n",
    "    Conv1D(64, 5, padding='same', activation='relu'),\n",
    "    MaxPooling1D(),\n",
    "    Dropout(0.6),\n",
    "    \n",
    "    # FC layers wiht BatchNorm\n",
    "    Flatten(),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.7),\n",
    "    Dense(100, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.7),\n",
    "    Dense(1, activation='sigmoid')])\n",
    "\n",
    "\n",
    "vgg_model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "vgg_model.optimizer.lr = 10e-3\n",
    "vgg_model.fit(train_content_idx, train_df.CLASS, validation_data=(valid_content_idx, valid_df.CLASS), \n",
    "              epochs=10, batch_size=64)\n",
    "vgg_model.optimizer.lr = 10e-4\n",
    "vgg_model.fit(train_content_idx, train_df.CLASS, validation_data=(valid_content_idx, valid_df.CLASS), \n",
    "              epochs=40, batch_size=64)\n",
    "vgg_model.optimizer.lr = 10e-5\n",
    "vgg_model.fit(train_content_idx, train_df.CLASS, validation_data=(valid_content_idx, valid_df.CLASS), \n",
    "              epochs=40, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00021692],\n",
       "       [ 0.00022692],\n",
       "       [ 0.00020616],\n",
       "       [ 0.00021896],\n",
       "       [ 0.00024789]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_spams = ['lol love it', 'awesome video', 'i love this song', 'so many views', 'she must have so much money']\n",
    "spams = ['check my channel', 'want to have more money contact me mail', 'email me to earn a lot of money',\n",
    "         'email me to at agne@gmal.com', 'suscribe to my yt channel', 'http://salut.com']\n",
    "\n",
    "spams = [words2idxs(format_phrase(spam)) for spam in spams]\n",
    "non_spams = [words2idxs(format_phrase(spam)) for spam in non_spams]\n",
    "\n",
    "\n",
    "spams = sequence.pad_sequences(spams, maxlen=maxlen, value=-1)\n",
    "non_spams = sequence.pad_sequences(non_spams, maxlen=maxlen, value=-1)\n",
    "\n",
    "vgg_model.predict(non_spams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00],\n",
       "       [  3.19520719e-02],\n",
       "       [  8.76859762e-04],\n",
       "       [  7.98932850e-01],\n",
       "       [  9.99083638e-01],\n",
       "       [  9.99604404e-01]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model.predict(spams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
